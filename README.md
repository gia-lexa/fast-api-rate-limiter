# Advanced Rate Limiting Strategies in FastAPI ğŸš€

## Overview
An advanced exploration of high-performance rate limiting, leveraging Redis for precision control and scalability.

## System Design
The system is designed for **high-throughput APIs** handling **millions of requests** while preventing abuse. It efficiently tracks request counts using **Redis** with **O(log n) time complexity** for rate checks. Optimized **expiry policies** ensure **minimal memory overhead**.

### Architecture Diagram
```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     Client Requests API       â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Rate Limiter (FastAPI + Redis) â”‚
   â”‚  â”œâ”€â”€ Fixed Window              â”‚
   â”‚  â”œâ”€â”€ Sliding Window            â”‚
   â”‚  â”œâ”€â”€ Token Bucket              â”‚
   â”‚  â”œâ”€â”€ Leaky Bucket              â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚         API Service Layer      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Algorithm Choices
Each algorithm is optimized for different use cases. The current main.py implements Leaky Bucket, but earlier commits of that file show the implementations of Fixed Window and Sliding Window. 

- **Fixed Window** â€“ Simple but allows bursts at window edges
- **Sliding Window** â€“ More accurate, avoids bursts
- **Leaky Bucket** â€“ Ensures a **smooth** request flow
- **Token Bucket** â€“ Allows short bursts while enforcing long-term limits

## Performance Benchmarks
```
Rate Limiter Performance (Benchmark @ 10,000 requests):
-------------------------------------------------------
âœ” Fixed Window    â†’  120Î¼s avg latency, O(1) Redis ops
âœ” Sliding Window  â†’  150Î¼s avg latency, O(log n) Redis ops
âœ” Leaky Bucket    â†’  130Î¼s avg latency, O(1) Redis ops
```
ğŸ“Œ Designed for **low-latency enforcement** and **high scalability**.

## Trade-offs & Considerations
**Distributed Systems Considerations:**
- **Race conditions** are handled via atomic Redis operations (`INCR`, `ZADD`).
- Can be extended for **multi-node rate limiting** using **Redis Cluster** or **consistent hashing**.
- Supports **dynamic rate limits** (e.g., per-user tiers, API keys).

## Future Enhancements Currently In-Progress
âœ… **JWT-Based API Rate Limits** â€“ Per-user quotas instead of IP-based limits

âœ… **Rate Limit Adaptation** â€“ Machine learning to dynamically adjust limits

âœ… **Prometheus + Grafana Monitoring** â€“ Real-time dashboards

## Disclaimer
This project is an in-progress **technical demonstration** of advanced rate-limiting strategies. While provided under the MIT License, it is **not optimized for production use**, and no guarantees are made regarding security, reliability, or real-world performance. It serves as an exploration of best practices in scalable rate limiting.

---
ğŸš€ **This project showcases production-level rate limiting strategies, balancing speed, fairness, and resilience for high-scale APIs.**

