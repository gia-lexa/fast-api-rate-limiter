# Advanced Rate Limiting Strategies in FastAPI ğŸš€

## Overview
A high-performance API rate limiter implementing **Fixed Window, Sliding Window, Token Bucket, and Leaky Bucket** algorithms using **FastAPI + Redis**. Optimized for **scalability**, **low-latency enforcement**, and **distributed API rate control**.

## System Design
The system is designed for **high-throughput APIs** handling **millions of requests** while preventing abuse. It efficiently tracks request counts using **Redis** with **O(log n) time complexity** for rate checks. Optimized **expiry policies** ensure **minimal memory overhead**.

### Architecture Diagram
```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     Client Requests API       â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Rate Limiter (FastAPI + Redis) â”‚
   â”‚  â”œâ”€â”€ Fixed Window              â”‚
   â”‚  â”œâ”€â”€ Sliding Window            â”‚
   â”‚  â”œâ”€â”€ Token Bucket              â”‚
   â”‚  â”œâ”€â”€ Leaky Bucket              â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚         API Service Layer      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Algorithm Choices
Each algorithm is optimized for different use cases:

- **Fixed Window** â€“ Simple but allows bursts at window edges
- **Sliding Window** â€“ More accurate, avoids bursts
- **Token Bucket** â€“ Allows short bursts while enforcing long-term limits
- **Leaky Bucket** â€“ Ensures a **smooth** request flow

## Performance Benchmarks
```
Rate Limiter Performance (Benchmark @ 10,000 requests):
-------------------------------------------------------
âœ” Fixed Window    â†’  120Î¼s avg latency, O(1) Redis ops
âœ” Sliding Window  â†’  150Î¼s avg latency, O(log n) Redis ops
âœ” Token Bucket    â†’  140Î¼s avg latency, O(1) Redis ops
âœ” Leaky Bucket    â†’  130Î¼s avg latency, O(1) Redis ops
```
ğŸ“Œ Designed for **low-latency enforcement** and **high scalability**.

## Trade-offs & Considerations
**Distributed Systems Considerations:**
- **Race conditions** are handled via atomic Redis operations (`INCR`, `ZADD`).
- Can be extended for **multi-node rate limiting** using **Redis Cluster** or **consistent hashing**.
- Supports **dynamic rate limits** (e.g., per-user tiers, API keys).

## In Progress Enhancements
âœ… **JWT-Based API Rate Limits** â€“ Per-user quotas instead of IP-based limits
âœ… **Rate Limit Adaptation** â€“ Machine learning to dynamically adjust limits
âœ… **Prometheus + Grafana Monitoring** â€“ Real-time dashboards

---

## Disclaimer  
This project is a technical demonstration of advanced rate-limiting strategies. It is not intended for deployment in real-world environments but serves as an exploration of best practices in scalable rate limiting.


